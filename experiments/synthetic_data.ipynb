{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c28e5c1db8448898fe9fed0c9eec3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixuanyi/anaconda3/envs/rlbn/lib/python3.6/site-packages/pgmpy/utils/mathext.py:84: UserWarning: Probability values don't exactly sum to 1. Differ by: 9.999999999998899e-05. Adjusting values.\n",
      "  f\"Probability values don't exactly sum to 1. Differ by: {error}. Adjusting values.\"\n",
      "/home/lixuanyi/anaconda3/envs/rlbn/lib/python3.6/site-packages/pgmpy/utils/mathext.py:84: UserWarning: Probability values don't exactly sum to 1. Differ by: -9.999999999998899e-05. Adjusting values.\n",
      "  f\"Probability values don't exactly sum to 1. Differ by: {error}. Adjusting values.\"\n",
      "/home/lixuanyi/anaconda3/envs/rlbn/lib/python3.6/site-packages/pgmpy/utils/mathext.py:84: UserWarning: Probability values don't exactly sum to 1. Differ by: -0.00010000000000021103. Adjusting values.\n",
      "  f\"Probability values don't exactly sum to 1. Differ by: {error}. Adjusting values.\"\n",
      "/home/lixuanyi/anaconda3/envs/rlbn/lib/python3.6/site-packages/pgmpy/utils/mathext.py:84: UserWarning: Probability values don't exactly sum to 1. Differ by: 1.1102230246251565e-16. Adjusting values.\n",
      "  f\"Probability values don't exactly sum to 1. Differ by: {error}. Adjusting values.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472dd96905174f509c747f0f61260e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixuanyi/anaconda3/envs/rlbn/lib/python3.6/site-packages/pgmpy/utils/mathext.py:84: UserWarning: Probability values don't exactly sum to 1. Differ by: 0.00010000000000010001. Adjusting values.\n",
      "  f\"Probability values don't exactly sum to 1. Differ by: {error}. Adjusting values.\"\n"
     ]
    }
   ],
   "source": [
    "from utils import simulate_dag, simulate_parameter, simulate_linear_sem, simulate_noliner_bn, simulate_nonlinear_sem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# nodes_edges = [(10, 20), (20, 40), (40, 80)]\n",
    "nodes_edges = [(40, 40), (80, 80)]\n",
    "sample_size = 10000\n",
    "\n",
    "# for time in range(1):\n",
    "for (node, edge) in nodes_edges:\n",
    "    B_true = simulate_dag(node, edge, 'ER')\n",
    "    W_true = simulate_parameter(B_true)\n",
    "    bn_data = simulate_noliner_bn(B_true, sample_size)\n",
    "    data = simulate_linear_sem(W_true, sample_size, 'logistic')\n",
    "    gaussian_data = simulate_linear_sem(W_true, sample_size, 'gauss')\n",
    "    # gp_data = simulate_nonlinear_sem(W_true, sample_size, 'gp')\n",
    "    # rl_bic_data_path = \"Causal_Discovery_RL/src/data/synthetic_n{}_e{}\".format(node, edge)\n",
    "    data_path = \"data/synthetic_n{}_e{}_{}\".format(node, edge, sample_size)\n",
    "    bn_data_path = \"data/synthetic_bn_n{}_e{}_{}\".format(node, edge, sample_size)\n",
    "    gauss_data_path = \"data/synthetic_gauss_n{}_e{}_{}\".format(node, edge, sample_size)\n",
    "    # gp_data_path = \"data/synthetic_gp_n{}_e{}_{}\".format(node, edge, time)\n",
    "    if os.path.exists(data_path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(data_path)\n",
    "    if os.path.exists(bn_data_path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(bn_data_path)\n",
    "    if os.path.exists(gauss_data_path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(gauss_data_path)\n",
    "    # if os.path.exists(gp_data_path):\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     os.mkdir(gp_data_path)\n",
    "\n",
    "    datadf = pd.DataFrame(data, columns=[str(i) for i in range(node)])\n",
    "    bndatadf = pd.DataFrame(bn_data, columns=[str(i) for i in range(node)])\n",
    "    gaussdatadf = pd.DataFrame(gaussian_data, columns=[str(i) for i in range(node)])\n",
    "    # gpdatadf = pd.DataFrame(gp_data, columns=[str(i) for i in range(node)])\n",
    "    b_df = pd.DataFrame(B_true)\n",
    "    np.save(data_path+'/DAG.npy', B_true)\n",
    "    np.save(data_path+'/data.npy', data)\n",
    "    np.save(bn_data_path+'/DAG.npy', B_true)\n",
    "    np.save(bn_data_path+'/data.npy', bn_data)\n",
    "    np.save(gauss_data_path+'/DAG.npy', B_true)\n",
    "    np.save(gauss_data_path+'/data.npy', gaussian_data)\n",
    "    # np.save(gp_data_path+'/DAG.npy', B_true)\n",
    "    # np.save(gp_data_path+'/data.npy', gp_data)\n",
    "\n",
    "    # datadf.to_csv(\"../data/synthetic_n{}_e{}_{}.csv\".format(node, edge, time), index=False)\n",
    "    # bndatadf.to_csv(\"../data/synthetic_bn_n{}_e{}_{}.csv\".format(node, edge, time), index=False)\n",
    "    datadf.to_csv(data_path+'/data.csv', index=False)\n",
    "    bndatadf.to_csv(bn_data_path+'/data.csv', index=False)\n",
    "    gaussdatadf.to_csv(gauss_data_path+'/data.csv', index=False)\n",
    "    # gpdatadf.to_csv(gp_data_path+'/data.csv', index=False)\n",
    "\n",
    "    b_df.to_csv(data_path+'/DAG.csv', index=False)\n",
    "    b_df.to_csv(bn_data_path+'/DAG.csv', index=False)\n",
    "    b_df.to_csv(gauss_data_path+'/DAG.csv', index=False)\n",
    "    # b_df.to_csv(gp_data_path+'/DAG.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bc1e5592914c73b9a2d755dc16afd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixuanyi/anaconda3/envs/rlbn/lib/python3.6/site-packages/pgmpy/utils/mathext.py:84: UserWarning: Probability values don't exactly sum to 1. Differ by: -9.999999999998899e-05. Adjusting values.\n",
      "  f\"Probability values don't exactly sum to 1. Differ by: {error}. Adjusting values.\"\n",
      "/home/lixuanyi/anaconda3/envs/rlbn/lib/python3.6/site-packages/pgmpy/utils/mathext.py:84: UserWarning: Probability values don't exactly sum to 1. Differ by: 9.999999999998899e-05. Adjusting values.\n",
      "  f\"Probability values don't exactly sum to 1. Differ by: {error}. Adjusting values.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca43b943230413d85c92216ff4ea73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import simulate_dag, simulate_parameter, simulate_linear_sem, simulate_noliner_bn_2, simulate_nonlinear_sem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# nodes_edges = [(10, 20), (20, 40), (40, 80)]\n",
    "nodes_edges = [(60, 60)]\n",
    "sample_size1 = 2000\n",
    "sample_size2 = 10000\n",
    "\n",
    "for (node, edge) in nodes_edges:\n",
    "    B_true = simulate_dag(node, edge, 'ER')\n",
    "    bn_data1, bn_data2 = simulate_noliner_bn_2(B_true, sample_size1, sample_size2)\n",
    "\n",
    "    bn_data_path1 = \"data/ct_bn_n{}_e{}_{}\".format(node, edge, sample_size1)\n",
    "    bn_data_path2 = \"data/ct_bn_n{}_e{}_{}\".format(node, edge, sample_size2)\n",
    "\n",
    "    if os.path.exists(bn_data_path1):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(bn_data_path1)\n",
    "    if os.path.exists(bn_data_path2):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(bn_data_path2)\n",
    "\n",
    "    bndatadf1 = pd.DataFrame(bn_data1, columns=[str(i) for i in range(node)])\n",
    "    bndatadf2 = pd.DataFrame(bn_data2, columns=[str(i) for i in range(node)])\n",
    "    # gpdatadf = pd.DataFrame(gp_data, columns=[str(i) for i in range(node)])\n",
    "    b_df = pd.DataFrame(B_true)\n",
    "\n",
    "    np.save(bn_data_path1+'/DAG.npy', B_true)\n",
    "    np.save(bn_data_path1+'/data.npy', bn_data1)\n",
    "    np.save(bn_data_path2+'/DAG.npy', B_true)\n",
    "    np.save(bn_data_path2+'/data.npy', bn_data2)\n",
    "\n",
    "    bndatadf1.to_csv(bn_data_path1+'/data.csv', index=False)\n",
    "    b_df.to_csv(bn_data_path1+'/DAG.csv', index=False)\n",
    "    bndatadf2.to_csv(bn_data_path2+'/data.csv', index=False)\n",
    "    b_df.to_csv(bn_data_path2+'/DAG.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.load(\"data/data_p20_e80_n1000_GP/DAG.npy\")\n",
    "data = np.load(\"data/data_p20_e80_n1000_GP/data.npy\")\n",
    "\n",
    "graphdf = pd.DataFrame(graph)\n",
    "datadf = pd.DataFrame(data)\n",
    "graphdf.to_csv(\"data/data_p20_e80_n1000_GP/DAG.csv\", index=False)\n",
    "datadf.to_csv(\"data/data_p20_e80_n1000_GP/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnlearn as bn\n",
    "from pgmpy import readwrite\n",
    "from pgmpy.models import BayesianModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bifmodel = readwrite.BIF.BIFReader(path=\"data/bif/insurance.bif\")\n",
    "datadf = pd.read_csv(\"data/insurance/data.csv\")\n",
    "nodes = datadf.columns\n",
    "model = BayesianModel(bifmodel.variable_edges)\n",
    "model.name = bifmodel.network_name\n",
    "model.add_nodes_from(bifmodel.variable_names)\n",
    "a = len(nodes)\n",
    "w_g = np.zeros((a,a))\n",
    "for (i,j) in model.edges():\n",
    "    w_g[list(nodes).index(i),list(nodes).index(j)] = 1\n",
    "# list(nodes).index('asia')\n",
    "np.save('data/insurance/DAG.npy', w_g)\n",
    "np.save('data/insurance/data.npy', datadf.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data/insurance/data.csv: 100%|█████████████████████████████|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-Likelihood : -77082.78585400715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-77082.78585400715"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyAgrum as gum\n",
    "import os\n",
    "\n",
    "os.mkdir(\"data/insurance\")\n",
    "bn=gum.loadBN(\"data/bif/insurance.bif\")\n",
    "gum.generateCSV(bn,\"data/insurance/data.csv\",4096,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyAgrum as gum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# nodes_edges = [(10, 22), (12, 30), (20, 30), (27, 60), (37, 50), (50, 100), (77, 300), (100, 300)]\n",
    "nodes_edges = [(5, 10)]\n",
    "for (node, edge) in nodes_edges:\n",
    "    gen = gum.BNGenerator()\n",
    "    bn = gen.generate(node, edge)\n",
    "    gendata = gum.BNDatabaseGenerator(bn)\n",
    "    gendata.drawSamples(4096)\n",
    "\n",
    "    os.mkdir(\"data/syn_n{}_e{}\".format(node,edge))\n",
    "    gendata.toCSV(\"data/syn_n{}_e{}/data.csv\".format(node,edge))\n",
    "    bn.saveBIF(\"data/bif/syn_n{}_e{}.bif\".format(node,edge))\n",
    "\n",
    "    w_g = np.zeros((node,node))\n",
    "    for (i,j) in bn.arcs():\n",
    "        w_g[i,j] = 1\n",
    "    datadf = pd.read_csv(\"data/syn_n{}_e{}/data.csv\".format(node,edge))\n",
    "    # np.save('data/syn_n{}_e{}/DAG.npy'.format(node,edge), w_g)\n",
    "    np.save('data/syn_n{}_e{}/data.npy'.format(node,edge), datadf.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datanp = np.load(\"data/gp_n10_e10/data.npy\")\n",
    "datadf = pd.DataFrame(datanp)\n",
    "datadf.to_csv(\"data/gp_n10_e10/data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cedb9ad5d8ca8e9f374c9a1f948484700d1a001944ad34aa0c9ee8d7ff94b684"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('rlbn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
